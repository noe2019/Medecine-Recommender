{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c755214a",
   "metadata": {},
   "source": [
    "## **Title:** Building a Disease Diagnosis and Prescription Recommendation System with Machine Learning  \n",
    "\n",
    "**Description:**  \n",
    "Explore our advanced Personalized Medical Recommendation System, powered by machine learning. This innovative platform analyzes symptoms to accurately predict potential diseases, helping users better understand and manage their health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db119e1e",
   "metadata": {},
   "source": [
    "# 1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e4766bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4920, 133)\n",
      "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
      "0        1          1                     1                    0          0   \n",
      "1        0          1                     1                    0          0   \n",
      "2        1          0                     1                    0          0   \n",
      "3        1          1                     0                    0          0   \n",
      "4        1          1                     1                    0          0   \n",
      "\n",
      "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
      "0       0           0             0        0                 0  ...   \n",
      "1       0           0             0        0                 0  ...   \n",
      "2       0           0             0        0                 0  ...   \n",
      "3       0           0             0        0                 0  ...   \n",
      "4       0           0             0        0                 0  ...   \n",
      "\n",
      "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
      "0           0         0             0                    0   \n",
      "1           0         0             0                    0   \n",
      "2           0         0             0                    0   \n",
      "3           0         0             0                    0   \n",
      "4           0         0             0                    0   \n",
      "\n",
      "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
      "0                     0                   0        0                     0   \n",
      "1                     0                   0        0                     0   \n",
      "2                     0                   0        0                     0   \n",
      "3                     0                   0        0                     0   \n",
      "4                     0                   0        0                     0   \n",
      "\n",
      "   yellow_crust_ooze         prognosis  \n",
      "0                  0  Fungal infection  \n",
      "1                  0  Fungal infection  \n",
      "2                  0  Fungal infection  \n",
      "3                  0  Fungal infection  \n",
      "4                  0  Fungal infection  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "dataset = pd.read_csv('datasets/Training.csv')\n",
    "print(dataset.shape)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db916ab",
   "metadata": {},
   "source": [
    "# 2. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1e9c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Splitting features (X) and target variable (y)\n",
    "X = dataset.drop('prognosis', axis=1)\n",
    "y = dataset['prognosis']\n",
    "\n",
    "# Encoding the 'prognosis' column (target variable)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)  # Encode target variable\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a9ed2",
   "metadata": {},
   "source": [
    "# 3. Training & Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9c4a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC F1-Score: 1.00\n",
      "SVC Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "RandomForest F1-Score: 1.00\n",
      "RandomForest Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "GradientBoosting F1-Score: 1.00\n",
      "GradientBoosting Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost F1-Score: 0.10\n",
      "AdaBoost Confusion Matrix:\n",
      "[[0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " ...,\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Bagging F1-Score: 1.00\n",
      "Bagging Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "KNeighbors F1-Score: 1.00\n",
      "KNeighbors Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "MultinomialNB F1-Score: 1.00\n",
      "MultinomialNB Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "GaussianNB F1-Score: 1.00\n",
      "GaussianNB Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "LogisticRegression F1-Score: 1.00\n",
      "LogisticRegression Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "DecisionTree F1-Score: 1.00\n",
      "DecisionTree Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary to store models\n",
    "models = {\n",
    "    'SVC': SVC(kernel='linear'),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "    'Bagging': BaggingClassifier(n_estimators=10, random_state=42),\n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through the models, train, test, and print results\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    print(f\"{model_name} F1-Score: {f1:.2f}\")\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e77d8-6676-4a57-aa19-d8f28135bd6f",
   "metadata": {},
   "source": [
    "Given the identical F1-scores and confusion matrices for most models (all at 1.00 except for AdaBoost), the decision-making criteria should go beyond simple performance metrics to consider the following factors:\n",
    "\n",
    "### 1. Model Interpretability:\n",
    "\n",
    "**Best Choice**: DecisionTree, LogisticRegression\n",
    "Decision trees are highly interpretable, making it easy to understand feature importance and decision-making paths.\n",
    "Logistic regression provides insights into feature contributions via coefficients.\n",
    "### 2. Scalability and Computational Cost:\n",
    "\n",
    "**Best Choice**: MultinomialNB, GaussianNB, LogisticRegression, KNeighbors\n",
    "These models tend to have lower computational requirements, especially for large datasets.\n",
    "### 3. Overfitting Risk:\n",
    "\n",
    "**Best Choice**: Bagging, RandomForest, GradientBoosting\n",
    "These ensemble methods are generally more robust to overfitting compared to a single decision tree.\n",
    "### 4. Data Characteristics and Use Case:\n",
    "\n",
    "**Sparse or Text Data**: MultinomialNB, LogisticRegression\n",
    "Continuous Data or Multi-class Settings: GaussianNB, KNeighbors\n",
    "### 5. Deployment Requirements:\n",
    "\n",
    "**Best Choice**: LogisticRegression, SVC\n",
    "Logistic regression and support vector classifiers are straightforward to deploy due to simpler parameter tuning.\n",
    "Warnings/Issues:\n",
    "\n",
    "Avoid using AdaBoost due to its poor F1 score (0.10) and the deprecation warning for the SAMME.R algorithm.\n",
    "### 6. Recommendation:\n",
    "**Primary Choice**: If interpretability is key, go with Logistic Regression or Decision Tree.\n",
    "\n",
    "**Secondary Choice**: For scalability and robustness, choose Random Forest or Gradient Boosting.\n",
    "\n",
    "**Avoid**: AdaBoost, due to its poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed0bab4a-b329-417f-97f5-2e05b6af78e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[40  0  0 ...  0  0  0]\n",
      " [ 0 43  0 ...  0  0  0]\n",
      " [ 0  0 28 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 34  0  0]\n",
      " [ 0  0  0 ...  0 41  0]\n",
      " [ 0  0  0 ...  0  0 31]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        43\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        46\n",
      "           4       1.00      1.00      1.00        42\n",
      "           5       1.00      1.00      1.00        33\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        39\n",
      "           8       1.00      1.00      1.00        32\n",
      "           9       1.00      1.00      1.00        49\n",
      "          10       1.00      1.00      1.00        37\n",
      "          11       1.00      1.00      1.00        42\n",
      "          12       1.00      1.00      1.00        41\n",
      "          13       1.00      1.00      1.00        32\n",
      "          14       1.00      1.00      1.00        29\n",
      "          15       1.00      1.00      1.00        30\n",
      "          16       1.00      1.00      1.00        32\n",
      "          17       1.00      1.00      1.00        41\n",
      "          18       1.00      1.00      1.00        28\n",
      "          19       1.00      1.00      1.00        42\n",
      "          20       1.00      1.00      1.00        37\n",
      "          21       1.00      1.00      1.00        31\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        26\n",
      "          24       1.00      1.00      1.00        36\n",
      "          25       1.00      1.00      1.00        29\n",
      "          26       1.00      1.00      1.00        38\n",
      "          27       1.00      1.00      1.00        38\n",
      "          28       1.00      1.00      1.00        28\n",
      "          29       1.00      1.00      1.00        29\n",
      "          30       1.00      1.00      1.00        32\n",
      "          31       1.00      1.00      1.00        37\n",
      "          32       1.00      1.00      1.00        36\n",
      "          33       1.00      1.00      1.00        38\n",
      "          34       1.00      1.00      1.00        40\n",
      "          35       1.00      1.00      1.00        43\n",
      "          36       1.00      1.00      1.00        36\n",
      "          37       1.00      1.00      1.00        41\n",
      "          38       1.00      1.00      1.00        34\n",
      "          39       1.00      1.00      1.00        41\n",
      "          40       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "\n",
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "Feature Importances:\n",
      "                   Feature  Importance\n",
      "97             muscle_pain    0.022909\n",
      "33              dark_urine    0.018305\n",
      "41              mild_fever    0.017635\n",
      "0                  itching    0.017398\n",
      "109  lack_of_concentration    0.016288\n",
      "..                     ...         ...\n",
      "15             weight_gain    0.001601\n",
      "23   irregular_sugar_level    0.001493\n",
      "17    cold_hands_and_feets    0.001195\n",
      "70     puffy_face_and_eyes    0.001093\n",
      "45          fluid_overload    0.000000\n",
      "\n",
      "[132 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/random_forest_model.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Feature Importance (Optional)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Save the trained model (Optional)\n",
    "import joblib\n",
    "joblib.dump(rf_model, 'models/random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dd13145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "rf = joblib.load('models/random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "786bfd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions:\n",
      "Test 1:\n",
      "  Predicted Disease: 40\n",
      "  Actual Disease: 40\n",
      "----------------------------------------\n",
      "Test 101:\n",
      "  Predicted Disease: 39\n",
      "  Actual Disease: 39\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Function to test and display predictions for given indices\n",
    "def test_model(model, X_test, y_test, test_indices):\n",
    "    \"\"\"\n",
    "    Test and display predictions for specific indices.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model for predictions.\n",
    "    - X_test: Test feature set (pandas DataFrame or NumPy array).\n",
    "    - y_test: Test labels (pandas Series or NumPy array).\n",
    "    - test_indices: List of indices to test.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for idx in test_indices:\n",
    "        # Ensure index is valid\n",
    "        if idx >= len(X_test):\n",
    "            print(f\"Index {idx} is out of range. Skipping.\")\n",
    "            continue\n",
    "        # Convert X_test[idx] to array to avoid feature name warnings\n",
    "        X_sample = X_test.iloc[idx].values.reshape(1, -1) if hasattr(X_test, 'iloc') else X_test[idx].reshape(1, -1)\n",
    "        predicted = model.predict(X_sample)[0]\n",
    "        actual = y_test[idx]  # Access directly for NumPy arrays\n",
    "        print(f\"Test {idx + 1}:\")\n",
    "        print(f\"  Predicted Disease: {predicted}\")\n",
    "        print(f\"  Actual Disease: {actual}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Example usage\n",
    "test_indices_rf = [0, 100]  # Indices to test for Random Forest\n",
    "\n",
    "print(\"Random Forest Predictions:\")\n",
    "test_model(rf, X_test, y_test, test_indices_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6884a",
   "metadata": {},
   "source": [
    "# 4. Design the Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f59b8",
   "metadata": {},
   "source": [
    "## Load database and use logic for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c568f6b8-a3a5-4b93-b967-ae0d263eb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "767ed813",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_des = pd.read_csv(\"datasets/symtoms_df.csv\")\n",
    "precautions = pd.read_csv(\"datasets/precautions_df.csv\")\n",
    "workout = pd.read_csv(\"datasets/workout_df.csv\")\n",
    "description = pd.read_csv(\"datasets/description.csv\")\n",
    "medications = pd.read_csv('datasets/medications.csv')\n",
    "diets = pd.read_csv(\"datasets/diets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cb123a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def helper(dis, description, precautions, medications, diets, workout):\n",
    "    try:\n",
    "        desc = description[description['Disease'] == dis]['Description']\n",
    "        desc = \" \".join(desc.tolist())\n",
    "        pre = precautions[precautions['Disease'] == dis][['Precaution_1', 'Precaution_2', 'Precaution_3', 'Precaution_4']]\n",
    "        pre = pre.values.flatten().tolist()\n",
    "        med = medications[medications['Disease'] == dis]['Medication'].tolist()\n",
    "        diet = diets[diets['Disease'] == dis]['Diet'].tolist()\n",
    "        wrkout = workout[workout['disease'] == dis]['workout'].tolist()\n",
    "        return desc, pre, med, diet, wrkout\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving details for disease '{dis}': {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "# Prediction Function\n",
    "def get_predicted_disease(patient_symptoms, symptoms_dict, diseases_list, model, X_train=None):\n",
    "    \"\"\"\n",
    "    Predict the disease based on patient symptoms using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - patient_symptoms: List of symptoms provided by the patient.\n",
    "    - symptoms_dict: Dictionary mapping symptoms to indices.\n",
    "    - diseases_list: Dictionary mapping indices to diseases.\n",
    "    - model: Trained classification model (e.g., RandomForestClassifier or SVC).\n",
    "    - X_train: Optional, training data used for the model. Required for compatibility with older scikit-learn versions.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted disease (str) or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Determine input vector size\n",
    "        if hasattr(model, 'n_features_in_'):\n",
    "            input_vector_size = model.n_features_in_\n",
    "        elif X_train is not None:\n",
    "            input_vector_size = X_train.shape[1]\n",
    "        else:\n",
    "            raise ValueError(\"Model input size could not be determined. Provide X_train.\")\n",
    "\n",
    "        # Initialize input vector\n",
    "        input_vector = np.zeros(input_vector_size)\n",
    "\n",
    "        # Map symptoms to input vector\n",
    "        for symptom in patient_symptoms:\n",
    "            if symptom in symptoms_dict:\n",
    "                symptom_index = symptoms_dict[symptom]\n",
    "                if symptom_index < len(input_vector):\n",
    "                    input_vector[symptom_index] = 1\n",
    "                else:\n",
    "                    print(f\"Warning: Symptom index {symptom_index} is out of bounds.\")\n",
    "            else:\n",
    "                print(f\"Warning: Symptom '{symptom}' not recognized.\")\n",
    "\n",
    "        # Predict the disease\n",
    "        predicted_index = model.predict([input_vector])[0]\n",
    "        return diseases_list.get(predicted_index, \"Unknown Disease\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction Failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97dfb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions:\n",
      "Test 1:\n",
      "  Predicted Disease: 40\n",
      "  Actual Disease: 40\n",
      "----------------------------------------\n",
      "Test 101:\n",
      "  Predicted Disease: 39\n",
      "  Actual Disease: 39\n",
      "----------------------------------------\n",
      "Warning: Symptom 'dischromic _patches' not recognized.\n",
      "Predicted Disease: Fungal infection\n",
      "Description: Fungal infection is a common skin condition caused by fungi.\n",
      "Precautions: ['bath twice', 'use detol or neem in bathing water', 'keep infected area dry', 'use clean cloths']\n",
      "Medications: [\"['Antifungal Cream', 'Fluconazole', 'Terbinafine', 'Clotrimazole', 'Ketoconazole']\"]\n",
      "Diet: [\"['Antifungal Diet', 'Probiotics', 'Garlic', 'Coconut oil', 'Turmeric']\"]\n",
      "Workout: ['Avoid sugary foods', 'Consume probiotics', 'Increase intake of garlic', 'Include yogurt in diet', 'Limit processed foods', 'Stay hydrated', 'Consume green tea', 'Eat foods rich in zinc', 'Include turmeric in diet', 'Eat fruits and vegetables']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "try:\n",
    "    rf = joblib.load('models/random_forest_model.pkl')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"Random Forest model file not found. Ensure 'random_forest_model.pkl' is in the 'models' directory.\")\n",
    "\n",
    "# Function to test and display predictions for given indices\n",
    "def test_model(model, X_test, y_test, test_indices):\n",
    "    \"\"\"\n",
    "    Test and display predictions for specific indices.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model for predictions.\n",
    "    - X_test: Test feature set (pandas DataFrame or NumPy array).\n",
    "    - y_test: Test labels (pandas Series or NumPy array).\n",
    "    - test_indices: List of indices to test.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if X_test is None or y_test is None:\n",
    "        print(\"Error: X_test and y_test must be provided.\")\n",
    "        return\n",
    "\n",
    "    for idx in test_indices:\n",
    "        if idx >= len(X_test):\n",
    "            print(f\"Index {idx} is out of range. Skipping.\")\n",
    "            continue\n",
    "        # Handle data type and reshape for prediction\n",
    "        X_sample = X_test.iloc[idx].values.reshape(1, -1) if hasattr(X_test, 'iloc') else X_test[idx].reshape(1, -1)\n",
    "        predicted = model.predict(X_sample)[0]\n",
    "        actual = y_test[idx] if isinstance(y_test, np.ndarray) else y_test.iloc[idx]\n",
    "        print(f\"Test {idx + 1}:\")\n",
    "        print(f\"  Predicted Disease: {predicted}\")\n",
    "        print(f\"  Actual Disease: {actual}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Example: Test the Random Forest model\n",
    "test_indices_rf = [0, 100]  # Replace with indices from your dataset\n",
    "print(\"Random Forest Predictions:\")\n",
    "test_model(rf, X_test, y_test, test_indices_rf)\n",
    "\n",
    "# Load datasets\n",
    "sym_des = pd.read_csv(\"datasets/symtoms_df.csv\")\n",
    "precautions = pd.read_csv(\"datasets/precautions_df.csv\")\n",
    "workout = pd.read_csv(\"datasets/workout_df.csv\")\n",
    "description = pd.read_csv(\"datasets/description.csv\")\n",
    "medications = pd.read_csv(\"datasets/medications.csv\")\n",
    "diets = pd.read_csv(\"datasets/diets.csv\")\n",
    "\n",
    "# Helper Function\n",
    "def helper(dis, description, precautions, medications, diets, workout):\n",
    "    try:\n",
    "        desc = description[description['Disease'] == dis]['Description']\n",
    "        desc = \" \".join(desc.tolist())\n",
    "        pre = precautions[precautions['Disease'] == dis][['Precaution_1', 'Precaution_2', 'Precaution_3', 'Precaution_4']]\n",
    "        pre = pre.values.flatten().tolist()\n",
    "        med = medications[medications['Disease'] == dis]['Medication'].tolist()\n",
    "        diet = diets[diets['Disease'] == dis]['Diet'].tolist()\n",
    "        wrkout = workout[workout['disease'] == dis]['workout'].tolist()\n",
    "        return desc, pre, med, diet, wrkout\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving details for disease '{dis}': {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "# Prediction Function\n",
    "def get_predicted_disease(patient_symptoms, symptoms_dict, diseases_list, model, X_train=None):\n",
    "    \"\"\"\n",
    "    Predict the disease based on patient symptoms using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - patient_symptoms: List of symptoms provided by the patient.\n",
    "    - symptoms_dict: Dictionary mapping symptoms to indices.\n",
    "    - diseases_list: Dictionary mapping indices to diseases.\n",
    "    - model: Trained classification model (e.g., RandomForestClassifier or SVC).\n",
    "    - X_train: Optional, training data used for the model. Required for compatibility with older scikit-learn versions.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted disease (str) or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Determine input vector size\n",
    "        if hasattr(model, 'n_features_in_'):\n",
    "            input_vector_size = model.n_features_in_\n",
    "        elif X_train is not None:\n",
    "            input_vector_size = X_train.shape[1]\n",
    "        else:\n",
    "            raise ValueError(\"Model input size could not be determined. Provide X_train.\")\n",
    "\n",
    "        # Initialize input vector\n",
    "        input_vector = np.zeros(input_vector_size)\n",
    "\n",
    "        # Map symptoms to input vector\n",
    "        for symptom in patient_symptoms:\n",
    "            if symptom in symptoms_dict:\n",
    "                symptom_index = symptoms_dict[symptom]\n",
    "                if symptom_index < len(input_vector):\n",
    "                    input_vector[symptom_index] = 1\n",
    "                else:\n",
    "                    print(f\"Warning: Symptom index {symptom_index} is out of bounds.\")\n",
    "            else:\n",
    "                print(f\"Warning: Symptom '{symptom}' not recognized.\")\n",
    "\n",
    "        # Predict the disease\n",
    "        predicted_index = model.predict([input_vector])[0]\n",
    "        return diseases_list.get(predicted_index, \"Unknown Disease\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction Failed\"\n",
    "\n",
    "# Symptom dictionary\n",
    "symptoms_dict = {\n",
    "    'itching': 0,\n",
    "    'skin_rash': 1,\n",
    "    'nodal_skin_eruptions': 2,\n",
    "    'continuous_sneezing': 3,\n",
    "    'shivering': 4,\n",
    "    'chills': 5,\n",
    "    'joint_pain': 6,\n",
    "    'stomach_pain': 7,\n",
    "    'acidity': 8,\n",
    "    'ulcers_on_tongue': 9,\n",
    "    'muscle_wasting': 10,\n",
    "    'vomiting': 11,\n",
    "    'burning_micturition': 12,\n",
    "    'spotting_urination': 13,\n",
    "    'fatigue': 14,\n",
    "    'weight_gain': 15,\n",
    "    'anxiety': 16,\n",
    "    'cold_hands_and_feets': 17,\n",
    "    'mood_swings': 18,\n",
    "    'weight_loss': 19,\n",
    "    'restlessness': 20,\n",
    "    'lethargy': 21,\n",
    "    'patches_in_throat': 22,\n",
    "    'irregular_sugar_level': 23,\n",
    "    'cough': 24,\n",
    "    'high_fever': 25,\n",
    "    'sunken_eyes': 26,\n",
    "    'breathlessness': 27,\n",
    "    'sweating': 28,\n",
    "    'dehydration': 29,\n",
    "    'indigestion': 30,\n",
    "    'headache': 31,\n",
    "    'yellowish_skin': 32,\n",
    "    'dark_urine': 33,\n",
    "    'nausea': 34,\n",
    "    'loss_of_appetite': 35,\n",
    "    'pain_behind_the_eyes': 36,\n",
    "    'back_pain': 37,\n",
    "    'constipation': 38,\n",
    "    'abdominal_pain': 39,\n",
    "    'diarrhoea': 40,\n",
    "    'mild_fever': 41,\n",
    "    'yellow_urine': 42,\n",
    "    'yellowing_of_eyes': 43,\n",
    "    'acute_liver_failure': 44,\n",
    "    'fluid_overload': 45,\n",
    "    'swelling_of_stomach': 46,\n",
    "    'swelled_lymph_nodes': 47,\n",
    "    'malaise': 48,\n",
    "    'blurred_and_distorted_vision': 49,\n",
    "    'phlegm': 50,\n",
    "    'throat_irritation': 51,\n",
    "    'redness_of_eyes': 52,\n",
    "    'sinus_pressure': 53,\n",
    "    'runny_nose': 54,\n",
    "    'congestion': 55,\n",
    "    'chest_pain': 56,\n",
    "    'weakness_in_limbs': 57,\n",
    "    'fast_heart_rate': 58,\n",
    "    'pain_during_bowel_movements': 59,\n",
    "    'pain_in_anal_region': 60,\n",
    "    'bloody_stool': 61,\n",
    "    'irritation_in_anus': 62,\n",
    "    'neck_pain': 63,\n",
    "    'dizziness': 64,\n",
    "    'cramps': 65,\n",
    "    'bruising': 66,\n",
    "    'obesity': 67,\n",
    "    'swollen_legs': 68,\n",
    "    'swollen_blood_vessels': 69,\n",
    "    'puffy_face_and_eyes': 70,\n",
    "    'enlarged_thyroid': 71,\n",
    "    'brittle_nails': 72,\n",
    "    'swollen_extremities': 73,\n",
    "    'excessive_hunger': 74,\n",
    "    'extra_marital_contacts': 75,\n",
    "    'drying_and_tingling_lips': 76,\n",
    "    'slurred_speech': 77,\n",
    "    'knee_pain': 78,\n",
    "    'hip_joint_pain': 79,\n",
    "    'muscle_weakness': 80,\n",
    "    'stiff_neck': 81,\n",
    "    'swelling_joints': 82,\n",
    "    'movement_stiffness': 83,\n",
    "    'spinning_movements': 84,\n",
    "    'loss_of_balance': 85,\n",
    "    'unsteadiness': 86,\n",
    "    'weakness_of_one_body_side': 87,\n",
    "    'loss_of_smell': 88,\n",
    "    'bladder_discomfort': 89,\n",
    "    'foul_smell_of_urine': 90,\n",
    "    'continuous_feel_of_urine': 91,\n",
    "    'passage_of_gases': 92,\n",
    "    'internal_itching': 93,\n",
    "    'toxic_look_typhos': 94,\n",
    "    'depression': 95,\n",
    "    'irritability': 96,\n",
    "    'muscle_pain': 97,\n",
    "    'altered_sensorium': 98,\n",
    "    'red_spots_over_body': 99,\n",
    "    'belly_pain': 100,\n",
    "    'abnormal_menstruation': 101,\n",
    "    'dischromic_patches': 102,\n",
    "    'watering_from_eyes': 103,\n",
    "    'increased_appetite': 104,\n",
    "    'polyuria': 105,\n",
    "    'family_history': 106,\n",
    "    'mucoid_sputum': 107,\n",
    "    'rusty_sputum': 108,\n",
    "    'lack_of_concentration': 109,\n",
    "    'visual_disturbances': 110,\n",
    "    'receiving_blood_transfusion': 111,\n",
    "    'receiving_unsterile_injections': 112,\n",
    "    'coma': 113,\n",
    "    'stomach_bleeding': 114,\n",
    "    'distention_of_abdomen': 115,\n",
    "    'history_of_alcohol_consumption': 116,\n",
    "    'fluid_overload.1': 117,\n",
    "    'blood_in_sputum': 118,\n",
    "    'prominent_veins_on_calf': 119,\n",
    "    'palpitations': 120,\n",
    "    'painful_walking': 121,\n",
    "    'pus_filled_pimples': 122,\n",
    "    'blackheads': 123,\n",
    "    'scurring': 124,\n",
    "    'skin_peeling': 125,\n",
    "    'silver_like_dusting': 126,\n",
    "    'small_dents_in_nails': 127,\n",
    "    'inflammatory_nails': 128,\n",
    "    'blister': 129,\n",
    "    'red_sore_around_nose': 130,\n",
    "    'yellow_crust_ooze': 131\n",
    "}\n",
    "\n",
    "diseases_list = {\n",
    "    0: '(vertigo) Paroymsal Positional Vertigo',\n",
    "    1: 'AIDS',\n",
    "    2: 'Acne',\n",
    "    3: 'Alcoholic hepatitis',\n",
    "    4: 'Allergy',\n",
    "    5: 'Arthritis',\n",
    "    6: 'Bronchial Asthma',\n",
    "    7: 'Cervical spondylosis',\n",
    "    8: 'Chicken pox',\n",
    "    9: 'Chronic cholestasis',\n",
    "    10: 'Common Cold',\n",
    "    11: 'Dengue',\n",
    "    12: 'Diabetes ',\n",
    "    13: 'Dimorphic hemmorhoids(piles)',\n",
    "    14: 'Drug Reaction',\n",
    "    15: 'Fungal infection',\n",
    "    16: 'GERD',\n",
    "    17: 'Gastroenteritis',\n",
    "    18: 'Heart attack',\n",
    "    19: 'Hepatitis B',\n",
    "    20: 'Hepatitis C',\n",
    "    21: 'Hepatitis D',\n",
    "    22: 'Hepatitis E',\n",
    "    23: 'Hypertension ',\n",
    "    24: 'Hyperthyroidism',\n",
    "    25: 'Hypoglycemia',\n",
    "    26: 'Hypothyroidism',\n",
    "    27: 'Impetigo',\n",
    "    28: 'Jaundice',\n",
    "    29: 'Malaria',\n",
    "    30: 'Migraine',\n",
    "    31: 'Osteoarthritis',\n",
    "    32: 'Paralysis (brain hemorrhage)',\n",
    "    33: 'Peptic ulcer disease',\n",
    "    34: 'Pneumonia',\n",
    "    35: 'Psoriasis',\n",
    "    36: 'Tuberculosis',\n",
    "    37: 'Typhoid',\n",
    "    38: 'Urinary tract infection',\n",
    "    39: 'Varicose veins',\n",
    "    40: 'hepatitis A'\n",
    "}\n",
    "# Patient symptoms\n",
    "patient_symptoms = ['itching', 'skin_rash', 'nodal_skin_eruptions', 'dischromic _patches']\n",
    "\n",
    "# Predict disease using Random Forest\n",
    "predicted_disease = get_predicted_disease(patient_symptoms, symptoms_dict, diseases_list, rf, X_train=X_train)\n",
    "\n",
    "# Retrieve details\n",
    "desc, pre, med, diet, wrkout = helper(predicted_disease, description, precautions, medications, diets, workout)\n",
    "\n",
    "# Display output\n",
    "print(f\"Predicted Disease: {predicted_disease}\")\n",
    "print(f\"Description: {desc}\")\n",
    "print(f\"Precautions: {pre}\")\n",
    "print(f\"Medications: {med}\")\n",
    "print(f\"Diet: {diet}\")\n",
    "print(f\"Workout: {wrkout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8d5df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "# let's use pycharm flask app\n",
    "# but install this version in pycharm\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be2b92-6c8d-4d30-9811-ca7fe9785287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
