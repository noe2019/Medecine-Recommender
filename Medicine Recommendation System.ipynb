{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c755214a",
   "metadata": {},
   "source": [
    "## **Title:** Building a Disease Diagnosis and Prescription Recommendation System with Machine Learning  \n",
    "\n",
    "**Description:**  \n",
    "Explore our advanced Personalized Medical Recommendation System, powered by machine learning. This innovative platform analyzes symptoms to accurately predict potential diseases, helping users better understand and manage their health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db119e1e",
   "metadata": {},
   "source": [
    "# 1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4766bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4920, 133)\n",
      "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
      "0        1          1                     1                    0          0   \n",
      "1        0          1                     1                    0          0   \n",
      "2        1          0                     1                    0          0   \n",
      "3        1          1                     0                    0          0   \n",
      "4        1          1                     1                    0          0   \n",
      "\n",
      "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
      "0       0           0             0        0                 0  ...   \n",
      "1       0           0             0        0                 0  ...   \n",
      "2       0           0             0        0                 0  ...   \n",
      "3       0           0             0        0                 0  ...   \n",
      "4       0           0             0        0                 0  ...   \n",
      "\n",
      "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
      "0           0         0             0                    0   \n",
      "1           0         0             0                    0   \n",
      "2           0         0             0                    0   \n",
      "3           0         0             0                    0   \n",
      "4           0         0             0                    0   \n",
      "\n",
      "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
      "0                     0                   0        0                     0   \n",
      "1                     0                   0        0                     0   \n",
      "2                     0                   0        0                     0   \n",
      "3                     0                   0        0                     0   \n",
      "4                     0                   0        0                     0   \n",
      "\n",
      "   yellow_crust_ooze         prognosis  \n",
      "0                  0  Fungal infection  \n",
      "1                  0  Fungal infection  \n",
      "2                  0  Fungal infection  \n",
      "3                  0  Fungal infection  \n",
      "4                  0  Fungal infection  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "dataset = pd.read_csv('datasets/Training.csv')\n",
    "print(dataset.shape)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db916ab",
   "metadata": {},
   "source": [
    "# 2. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e9c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Splitting features (X) and target variable (y)\n",
    "X = dataset.drop('prognosis', axis=1)\n",
    "y = dataset['prognosis']\n",
    "\n",
    "# Encoding the 'prognosis' column (target variable)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)  # Encode target variable\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a9ed2",
   "metadata": {},
   "source": [
    "# 3. Training & Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9c4a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC F1-Score: 1.00\n",
      "SVC Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "RandomForest F1-Score: 1.00\n",
      "RandomForest Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "GradientBoosting F1-Score: 1.00\n",
      "GradientBoosting Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost F1-Score: 0.10\n",
      "AdaBoost Confusion Matrix:\n",
      "[[0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " ...,\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0],\n",
      " [0, 0, 0, ..., 0, 0, 0]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Bagging F1-Score: 1.00\n",
      "Bagging Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "KNeighbors F1-Score: 1.00\n",
      "KNeighbors Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "MultinomialNB F1-Score: 1.00\n",
      "MultinomialNB Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "GaussianNB F1-Score: 1.00\n",
      "GaussianNB Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "LogisticRegression F1-Score: 1.00\n",
      "LogisticRegression Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n",
      "DecisionTree F1-Score: 1.00\n",
      "DecisionTree Confusion Matrix:\n",
      "[[40,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 43,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 34,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 41,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 31]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary to store models\n",
    "models = {\n",
    "    'SVC': SVC(kernel='linear'),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "    'Bagging': BaggingClassifier(n_estimators=10, random_state=42),\n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through the models, train, test, and print results\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    print(f\"{model_name} F1-Score: {f1:.2f}\")\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e77d8-6676-4a57-aa19-d8f28135bd6f",
   "metadata": {},
   "source": [
    "Given the identical F1-scores and confusion matrices for most models (all at 1.00 except for AdaBoost), the decision-making criteria should go beyond simple performance metrics to consider the following factors:\n",
    "\n",
    "### 1. Model Interpretability:\n",
    "\n",
    "**Best Choice**: DecisionTree, LogisticRegression\n",
    "Decision trees are highly interpretable, making it easy to understand feature importance and decision-making paths.\n",
    "Logistic regression provides insights into feature contributions via coefficients.\n",
    "### 2. Scalability and Computational Cost:\n",
    "\n",
    "**Best Choice**: MultinomialNB, GaussianNB, LogisticRegression, KNeighbors\n",
    "These models tend to have lower computational requirements, especially for large datasets.\n",
    "### 3. Overfitting Risk:\n",
    "\n",
    "**Best Choice**: Bagging, RandomForest, GradientBoosting\n",
    "These ensemble methods are generally more robust to overfitting compared to a single decision tree.\n",
    "### 4. Data Characteristics and Use Case:\n",
    "\n",
    "**Sparse or Text Data**: MultinomialNB, LogisticRegression\n",
    "Continuous Data or Multi-class Settings: GaussianNB, KNeighbors\n",
    "### 5. Deployment Requirements:\n",
    "\n",
    "**Best Choice**: LogisticRegression, SVC\n",
    "Logistic regression and support vector classifiers are straightforward to deploy due to simpler parameter tuning.\n",
    "Warnings/Issues:\n",
    "\n",
    "Avoid using AdaBoost due to its poor F1 score (0.10) and the deprecation warning for the SAMME.R algorithm.\n",
    "### 6. Recommendation:\n",
    "**Primary Choice**: If interpretability is key, go with Logistic Regression or Decision Tree.\n",
    "\n",
    "**Secondary Choice**: For scalability and robustness, choose Random Forest or Gradient Boosting.\n",
    "\n",
    "**Avoid**: AdaBoost, due to its poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0bab4a-b329-417f-97f5-2e05b6af78e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[40  0  0 ...  0  0  0]\n",
      " [ 0 43  0 ...  0  0  0]\n",
      " [ 0  0 28 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 34  0  0]\n",
      " [ 0  0  0 ...  0 41  0]\n",
      " [ 0  0  0 ...  0  0 31]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        43\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        46\n",
      "           4       1.00      1.00      1.00        42\n",
      "           5       1.00      1.00      1.00        33\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        39\n",
      "           8       1.00      1.00      1.00        32\n",
      "           9       1.00      1.00      1.00        49\n",
      "          10       1.00      1.00      1.00        37\n",
      "          11       1.00      1.00      1.00        42\n",
      "          12       1.00      1.00      1.00        41\n",
      "          13       1.00      1.00      1.00        32\n",
      "          14       1.00      1.00      1.00        29\n",
      "          15       1.00      1.00      1.00        30\n",
      "          16       1.00      1.00      1.00        32\n",
      "          17       1.00      1.00      1.00        41\n",
      "          18       1.00      1.00      1.00        28\n",
      "          19       1.00      1.00      1.00        42\n",
      "          20       1.00      1.00      1.00        37\n",
      "          21       1.00      1.00      1.00        31\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        26\n",
      "          24       1.00      1.00      1.00        36\n",
      "          25       1.00      1.00      1.00        29\n",
      "          26       1.00      1.00      1.00        38\n",
      "          27       1.00      1.00      1.00        38\n",
      "          28       1.00      1.00      1.00        28\n",
      "          29       1.00      1.00      1.00        29\n",
      "          30       1.00      1.00      1.00        32\n",
      "          31       1.00      1.00      1.00        37\n",
      "          32       1.00      1.00      1.00        36\n",
      "          33       1.00      1.00      1.00        38\n",
      "          34       1.00      1.00      1.00        40\n",
      "          35       1.00      1.00      1.00        43\n",
      "          36       1.00      1.00      1.00        36\n",
      "          37       1.00      1.00      1.00        41\n",
      "          38       1.00      1.00      1.00        34\n",
      "          39       1.00      1.00      1.00        41\n",
      "          40       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "\n",
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "Feature Importances:\n",
      "                   Feature  Importance\n",
      "97             muscle_pain    0.022909\n",
      "33              dark_urine    0.018305\n",
      "41              mild_fever    0.017635\n",
      "0                  itching    0.017398\n",
      "109  lack_of_concentration    0.016288\n",
      "..                     ...         ...\n",
      "15             weight_gain    0.001601\n",
      "23   irregular_sugar_level    0.001493\n",
      "17    cold_hands_and_feets    0.001195\n",
      "70     puffy_face_and_eyes    0.001093\n",
      "45          fluid_overload    0.000000\n",
      "\n",
      "[132 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/random_forest_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Feature Importance (Optional)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Save the trained model (Optional)\n",
    "import joblib\n",
    "joblib.dump(rf_model, 'models/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd13145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "rf = joblib.load('models/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786bfd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions:\n",
      "Test 1:\n",
      "  Predicted Disease: 40\n",
      "  Actual Disease: 40\n",
      "----------------------------------------\n",
      "Test 101:\n",
      "  Predicted Disease: 39\n",
      "  Actual Disease: 39\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Function to test and display predictions for given indices\n",
    "def test_model(model, X_test, y_test, test_indices):\n",
    "    \"\"\"\n",
    "    Test and display predictions for specific indices.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model for predictions.\n",
    "    - X_test: Test feature set (pandas DataFrame or NumPy array).\n",
    "    - y_test: Test labels (pandas Series or NumPy array).\n",
    "    - test_indices: List of indices to test.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for idx in test_indices:\n",
    "        # Ensure index is valid\n",
    "        if idx >= len(X_test):\n",
    "            print(f\"Index {idx} is out of range. Skipping.\")\n",
    "            continue\n",
    "        # Convert X_test[idx] to array to avoid feature name warnings\n",
    "        X_sample = X_test.iloc[idx].values.reshape(1, -1) if hasattr(X_test, 'iloc') else X_test[idx].reshape(1, -1)\n",
    "        predicted = model.predict(X_sample)[0]\n",
    "        actual = y_test[idx]  # Access directly for NumPy arrays\n",
    "        print(f\"Test {idx + 1}:\")\n",
    "        print(f\"  Predicted Disease: {predicted}\")\n",
    "        print(f\"  Actual Disease: {actual}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Example usage\n",
    "test_indices_rf = [0, 100]  # Indices to test for Random Forest\n",
    "\n",
    "print(\"Random Forest Predictions:\")\n",
    "test_model(rf_model, X_test, y_test, test_indices_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6884a",
   "metadata": {},
   "source": [
    "# 4. Design the Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f59b8",
   "metadata": {},
   "source": [
    "## Load database and use logic for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c568f6b8-a3a5-4b93-b967-ae0d263eb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "767ed813",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_des = pd.read_csv(\"datasets/symtoms_df.csv\")\n",
    "precautions = pd.read_csv(\"datasets/precautions_df.csv\")\n",
    "workout = pd.read_csv(\"datasets/workout_df.csv\")\n",
    "description = pd.read_csv(\"datasets/description.csv\")\n",
    "medications = pd.read_csv('datasets/medications.csv')\n",
    "diets = pd.read_csv(\"datasets/diets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cb123a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def helper(dis, description, precautions, medications, diets, workout):\n",
    "    try:\n",
    "        desc = description[description['Disease'] == dis]['Description']\n",
    "        desc = \" \".join(desc.tolist())\n",
    "        pre = precautions[precautions['Disease'] == dis][['Precaution_1', 'Precaution_2', 'Precaution_3', 'Precaution_4']]\n",
    "        pre = pre.values.flatten().tolist()\n",
    "        med = medications[medications['Disease'] == dis]['Medication'].tolist()\n",
    "        diet = diets[diets['Disease'] == dis]['Diet'].tolist()\n",
    "        wrkout = workout[workout['disease'] == dis]['workout'].tolist()\n",
    "        return desc, pre, med, diet, wrkout\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving details for disease '{dis}': {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "# Prediction Function\n",
    "def get_predicted_disease(patient_symptoms, symptoms_dict, diseases_list, model, X_train=None):\n",
    "    \"\"\"\n",
    "    Predict the disease based on patient symptoms using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - patient_symptoms: List of symptoms provided by the patient.\n",
    "    - symptoms_dict: Dictionary mapping symptoms to indices.\n",
    "    - diseases_list: Dictionary mapping indices to diseases.\n",
    "    - model: Trained classification model (e.g., RandomForestClassifier or SVC).\n",
    "    - X_train: Optional, training data used for the model. Required for compatibility with older scikit-learn versions.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted disease (str) or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Determine input vector size\n",
    "        if hasattr(model, 'n_features_in_'):\n",
    "            input_vector_size = model.n_features_in_\n",
    "        elif X_train is not None:\n",
    "            input_vector_size = X_train.shape[1]\n",
    "        else:\n",
    "            raise ValueError(\"Model input size could not be determined. Provide X_train.\")\n",
    "\n",
    "        # Initialize input vector\n",
    "        input_vector = np.zeros(input_vector_size)\n",
    "\n",
    "        # Map symptoms to input vector\n",
    "        for symptom in patient_symptoms:\n",
    "            if symptom in symptoms_dict:\n",
    "                symptom_index = symptoms_dict[symptom]\n",
    "                if symptom_index < len(input_vector):\n",
    "                    input_vector[symptom_index] = 1\n",
    "                else:\n",
    "                    print(f\"Warning: Symptom index {symptom_index} is out of bounds.\")\n",
    "            else:\n",
    "                print(f\"Warning: Symptom '{symptom}' not recognized.\")\n",
    "\n",
    "        # Predict the disease\n",
    "        predicted_index = model.predict([input_vector])[0]\n",
    "        return diseases_list.get(predicted_index, \"Unknown Disease\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction Failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "349c0c4b-10df-4788-8209-ae358b48484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during prediction: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "Predicted Disease: Prediction Failed\n",
      "Description: \n",
      "Precautions: []\n",
      "Medications: []\n",
      "Diet: []\n",
      "Workout: []\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "patient_symptoms = ['itching', 'skin_rash', 'fatigue']\n",
    "\n",
    "# Predict disease using Random Forest\n",
    "predicted_disease = get_predicted_disease(patient_symptoms, symptoms_dict, diseases_list, rf_model, X_train=X_train)\n",
    "\n",
    "# Retrieve details\n",
    "desc, pre, med, diet, wrkout = helper(predicted_disease, description, precautions, medications, diets, workout)\n",
    "\n",
    "# Display output\n",
    "print(f\"Predicted Disease: {predicted_disease}\")\n",
    "print(f\"Description: {desc}\")\n",
    "print(f\"Precautions: {pre}\")\n",
    "print(f\"Medications: {med}\")\n",
    "print(f\"Diet: {diet}\")\n",
    "print(f\"Workout: {wrkout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d5df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "# let's use pycharm flask app\n",
    "# but install this version in pycharm\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfb973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
